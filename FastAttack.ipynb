{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FastAttack.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zw8EKaPk4T5"
      },
      "source": [
        "# FastAttack - A fast and efficient attack framework on text classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__UW0T-KlHV2"
      },
      "source": [
        "## Installing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZeIFn6iC9FF"
      },
      "source": [
        "!pip install textattack\n",
        "!pip install -U gensim==4.0.0\n",
        "!pip install python-Levenshtein"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRCnFcOthRtZ"
      },
      "source": [
        "## For training a fasttext/word2vec embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbSBo02xDGO2"
      },
      "source": [
        "# import gensim.downloader as api\n",
        "# corpus = api.load('text8') # text8 is the corpus\n",
        "# from gensim.models.fasttext import FastText\n",
        "# model1 = FastText(corpus, sample = 0, sg = 1) # sg = Skipgram. Default: CBOW"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLiSrpmTErOs"
      },
      "source": [
        "# import gensim.downloader as api\n",
        "# corpus = api.load('text8')\n",
        "# from gensim.models.word2vec import Word2Vec\n",
        "# model2 = Word2Vec(corpus, sample = 0, sg = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbXFwDjphamI"
      },
      "source": [
        "## For loading a fasttext/word2vec embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCLiyaHYDBk1"
      },
      "source": [
        "from gensim.test.utils import get_tmpfile\n",
        "from gensim.models.fasttext import FastText \n",
        "model1 = FastText.load(\"FastAttack-models/fasttext.model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4jwSL5YDvPy"
      },
      "source": [
        "# from gensim.test.utils import get_tmpfile\n",
        "# from gensim.models.word2vec import Word2Vec\n",
        "# model2 = Word2Vec.load(\"FastAttack-models/word2vec.model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1xXXw5tFbuM"
      },
      "source": [
        "model1.wv.most_similar('cow')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkxgeerekx_O"
      },
      "source": [
        "Change the target model and dataset below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfecgI6BExUJ"
      },
      "source": [
        "# Import the model\n",
        "import transformers\n",
        "from textattack.models.tokenizers import AutoTokenizer\n",
        "from textattack.models.wrappers import HuggingFaceModelWrapper\n",
        "\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-ag-news\") # Change the target model here\n",
        "tokenizer = AutoTokenizer(\"textattack/bert-base-uncased-ag-news\") # Will be the same as the target model \n",
        "# Change these\n",
        "\n",
        "model_wrapper = HuggingFaceModelWrapper(model, tokenizer)\n",
        "dataset = HuggingFaceDataset(\"ag_news\", None, \"test\") # Change the dataset here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPj8fvaOFDAD"
      },
      "source": [
        "#Framing FastAttack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk84w4bSkUDP"
      },
      "source": [
        "## Defining our transformation. We choose the most appropriate replacement from a list of 10 closest neighbors of a given word in the embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHezFH9jE3Z2"
      },
      "source": [
        "from textattack.transformations import WordSwap\n",
        "\n",
        "class Swapper(WordSwap): # For fasttext\n",
        "    \"\"\" Transforms an input by replacing any word with its most similar counterpart\n",
        "    \"\"\"\n",
        "\n",
        "    # We don't need a constructor, since our class doesn't require any parameters.\n",
        "\n",
        "    def _get_replacement_words(self, word):\n",
        "        for i in range(10):\n",
        "            if word.lower() in model1.wv.most_similar(word)[i][0].lower():\n",
        "                continue # Don't return a word containing the exact word\n",
        "            elif word.isupper():\n",
        "                return [model1.wv.most_similar(word)[i][0].upper()] # Preserving case\n",
        "            elif word[0].isupper():\n",
        "                return [model1.wv.most_similar(word)[i][0].capitalize()] # Preserving Capitalization in words\n",
        "            else:\n",
        "                return [model1.wv.most_similar(word)[i][0]]\n",
        "            \n",
        "        return [model1.wv.most_similar(word)[0][0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZQeDr3JkXdX"
      },
      "source": [
        "## Constructing our attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm04Ri8WFGHy"
      },
      "source": [
        "from textattack.search_methods import GreedySearch\n",
        "from textattack.constraints.pre_transformation import RepeatModification, StopwordModification\n",
        "from textattack.shared import Attack\n",
        "from textattack.goal_functions import UntargetedClassification\n",
        "from textattack.datasets import HuggingFaceDataset\n",
        "\n",
        "# We're going to use our word swap class as the attack transformation.\n",
        "transformation = Swapper()\n",
        "# We'll constrain modification of already modified indices and stopwords\n",
        "constraints = [RepeatModification(),\n",
        "               StopwordModification()]\n",
        "# We'll use the Greedy search method\n",
        "search_method = GreedySearch()\n",
        "# Create the goal function using the model\n",
        "\n",
        "goal_function = UntargetedClassification(model_wrapper)\n",
        "\n",
        "# Now, let's make the attack from the 4 components:\n",
        "attack = Attack(goal_function, constraints, transformation, search_method)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a578fNbVFII3"
      },
      "source": [
        "print(attack)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANEUMHOphy93"
      },
      "source": [
        "## Printing results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp5uR4H7k1P0"
      },
      "source": [
        "Change the number of examples below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fClGtuFxFM5f"
      },
      "source": [
        "from collections import deque\n",
        "\n",
        "import textattack\n",
        "import tqdm\n",
        "import time\n",
        "from IPython.display import display, HTML\n",
        "num_examples = 25 # Number of examples to attack\n",
        "num_remaining_attacks = num_examples\n",
        "pbar = tqdm.tqdm(total=num_remaining_attacks, smoothing=0)\n",
        "\n",
        "worklist = deque(range(0, num_examples))\n",
        "worklist_tail = worklist[-1]\n",
        "\n",
        "attack_log_manager = textattack.loggers.AttackLogManager()\n",
        "\n",
        "load_time = time.time()\n",
        "        \n",
        "num_results = 0\n",
        "num_failures = 0\n",
        "num_successes = 0\n",
        "for result in attack.attack_dataset(dataset, indices=worklist):\n",
        "    result_html_str = result.__str__(color_method=\"html\").replace(\"\\n\\n\", \"<br>\")\n",
        "    display(HTML(result_html_str))\n",
        "    attack_log_manager.log_result(result)\n",
        "            \n",
        "    if not isinstance(result, textattack.attack_results.SkippedAttackResult):\n",
        "        pbar.update(1)\n",
        "    else:\n",
        "        worklist_tail += 1\n",
        "        pbar.update(1)\n",
        "        worklist.append(worklist_tail)\n",
        "\n",
        "    num_results += 1\n",
        "\n",
        "    if (\n",
        "        type(result) == textattack.attack_results.SuccessfulAttackResult\n",
        "        or type(result) == textattack.attack_results.MaximizedAttackResult\n",
        "    ):\n",
        "        num_successes += 1\n",
        "                \n",
        "    if type(result) == textattack.attack_results.FailedAttackResult:\n",
        "        num_failures += 1\n",
        "    pbar.set_description(\n",
        "        \"[Succeeded / Failed / Total] {} / {} / {}\".format(\n",
        "            num_successes, num_failures, num_results\n",
        "        )\n",
        "    )\n",
        "\n",
        "pbar.close()\n",
        "\n",
        "attack_log_manager.enable_stdout()\n",
        "attack_log_manager.log_summary()\n",
        "attack_log_manager.flush()\n",
        "        \n",
        "textattack.shared.logger.info(f\"Attack time: {time.time() - load_time}s\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}